{"cells":[{"cell_type":"markdown","metadata":{},"source":["Installing libraries"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -qU langgraph langchain langchain_openai langchain_community qdrant-client PyPDF2 beautifulsoup4 requests"]},{"cell_type":"markdown","metadata":{},"source":["Setting up imports"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["import os\n","import getpass\n","import logging\n","import json\n","import uuid\n","from typing import List, Dict, Any, Union, Annotated, Optional\n","from pathlib import Path\n","from tenacity import retry, stop_after_attempt, wait_exponential\n","\n","from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.agents import AgentExecutor, create_openai_functions_agent\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.tools import BaseTool, tool\n","from langgraph.graph import StateGraph, END\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_community.vectorstores import Qdrant\n","from qdrant_client import QdrantClient\n","from qdrant_client.http import models as rest\n","\n","# Set up API keys\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n","os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")"]},{"cell_type":"markdown","metadata":{},"source":["Create a working directory"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["# Create a working directory\n","WORKING_DIRECTORY = Path(\"./content/data\")\n","WORKING_DIRECTORY.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize Qdrant Client and OpenAI Embeddings"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# Initialize Qdrant client and OpenAI embeddings\n","qdrant_client = QdrantClient(\":memory:\")\n","embeddings = OpenAIEmbeddings()"]},{"cell_type":"markdown","metadata":{},"source":["State and Helper functions"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["class State(Dict[str, Any]):\n","    messages: Annotated[List[BaseMessage], operator.add]\n","    next: str\n","    documents: Dict[str, str]\n","\n","def get_last_message(state: State) -> str:\n","    return state[\"messages\"][-1].content\n","\n","def join_graph(response: dict):\n","    return {\"messages\": [response[\"messages\"][-1]]}\n","\n","def prelude(state):\n","    written_files = []\n","    try:\n","        written_files = [f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.glob(\"*\")]\n","    except:\n","        pass\n","    if not written_files:\n","        return {**state, \"current_files\": \"No files written.\"}\n","    return {\n","        **state,\n","        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n","        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["Setting up Vector Store"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["def initialize_vector_store():\n","    qdrant_client.recreate_collection(\n","        collection_name=\"sales_pitch_data\",\n","        vectors_config=rest.VectorParams(size=1536, distance=rest.Distance.COSINE),\n","    )\n","\n","def add_to_vector_store(text: str, metadata: Dict[str, Any]):\n","    vector = embeddings.embed_query(text)\n","    qdrant_client.upsert(\n","        collection_name=\"sales_pitch_data\",\n","        points=[rest.PointStruct(id=uuid.uuid4().hex, vector=vector, payload=metadata)],\n","    )\n","\n","def query_vector_store(query: str, limit: int = 5) -> List[Dict[str, Any]]:\n","    query_vector = embeddings.embed_query(query)\n","    search_result = qdrant_client.search(\n","        collection_name=\"sales_pitch_data\",\n","        query_vector=query_vector,\n","        limit=limit,\n","    )\n","    return [hit.payload for hit in search_result]"]},{"cell_type":"markdown","metadata":{},"source":["Tools"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["tavily_tool = TavilySearchResults(max_results=5)\n","\n","@tool\n","def linkedin_check(name: str, company: str) -> bool:\n","    \"\"\"Check if a person works at a specific company on LinkedIn.\"\"\"\n","    # Note: This is a mock implementation. In a real scenario, you'd use LinkedIn's API or web scraping.\n","    url = f\"https://www.linkedin.com/search/results/people/?keywords={name} {company}\"\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    return company.lower() in soup.text.lower()\n","\n","@tool\n","def read_document(\n","    file_name: Annotated[str, \"File path to read the document.\"],\n","    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n","    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",") -> str:\n","    \"\"\"Read the specified document.\"\"\"\n","    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n","        lines = file.readlines()\n","    if start is None:\n","        start = 0\n","    return \"\".join(lines[start:end])\n","\n","@tool\n","def write_document(\n","    content: Annotated[str, \"Text content to be written into the document.\"],\n","    state: Annotated[dict, \"The current state of the conversation.\"],\n",") -> Annotated[str, \"Path of the saved document file or error message.\"]:\n","    \"\"\"Create and save a text document.\"\"\"\n","    file_name = state.get(\"output_file\", \"output.txt\")\n","    file_path = WORKING_DIRECTORY / file_name\n","    logging.info(f\"Attempting to write document: {file_path}\")\n","    try:\n","        logging.debug(f\"Content to write: {content[:100]}...\")  # Log first 100 chars\n","        \n","        # Ensure the directory exists\n","        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","        \n","        with file_path.open(\"w\") as file:\n","            file.write(content)\n","        logging.info(f\"Successfully wrote content to {file_path}\")\n","        return f\"Document saved to {file_path}\"\n","    except IOError as e:\n","        error_msg = f\"IOError writing to {file_path}: {e}\"\n","        logging.error(error_msg)\n","        return error_msg\n","    except Exception as e:\n","        error_msg = f\"Unexpected error writing to {file_path}: {e}\"\n","        logging.error(error_msg)\n","        return error_msg\n","\n","@tool\n","def upload_document(file_path: str) -> str:\n","    \"\"\"Upload and read a document (PDF or text).\"\"\"\n","    file_extension = Path(file_path).suffix.lower()\n","    if file_extension == '.pdf':\n","        with open(file_path, 'rb') as file:\n","            pdf_reader = PyPDF2.PdfReader(file)\n","            text = \"\"\n","            for page in pdf_reader.pages:\n","                text += page.extract_text()\n","    elif file_extension in ['.txt', '.md']:\n","        with open(file_path, 'r') as file:\n","            text = file.read()\n","    else:\n","        raise ValueError(\"Unsupported file type. Please upload a PDF or text file.\")\n","    \n","    # Save the extracted text to a file in the working directory\n","    output_file = WORKING_DIRECTORY / f\"uploaded_document_{uuid.uuid4()}.txt\"\n","    with output_file.open(\"w\") as file:\n","        file.write(text)\n","    \n","    return f\"Document uploaded and saved as {output_file.name}\"\n","\n","@tool\n","def query_vector_db(query: str) -> str:\n","    \"\"\"Query the vector database for relevant information.\"\"\"\n","    results = query_vector_store(query)\n","    return \"\\n\".join([f\"{item['type']}: {item['content']}\" for item in results])"]},{"cell_type":"markdown","metadata":{},"source":["Agent Creation"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["def create_agent_node(name: str, tools: List[BaseTool], system_prompt: str):\n","    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n","    prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", system_prompt + \"\\n\\nAfter completing your task, you MUST use the write_document tool to save your output.\"),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ])\n","    agent = create_openai_functions_agent(llm, tools, prompt)\n","    agent_executor = AgentExecutor(agent=agent, tools=tools)\n","\n","    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n","    def execute_agent_with_retry(state):\n","        # Implementation omitted for brevity\n","        pass\n","\n","    def execute_agent(state):\n","        # Implementation omitted for brevity\n","        pass\n","\n","    return execute_agent"]},{"cell_type":"markdown","metadata":{},"source":["ComplanyResearchAlpha Function Definition"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["# Define the tools that CompanyResearchAlpha will use\n","company_research_tools = [\n","    tavily_tool,\n","    read_document,\n","    write_document,\n","    upload_document,\n","    query_vector_db\n","]\n","\n","# Create the CompanyResearchAlpha node\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    company_research_tools,\n","    \"\"\"You are a company research specialist. Your task is to gather initial information about the target company.\n","    Use the available tools to research the company and compile a brief summary including:\n","    1. Company name and basic description\n","    2. Industry\n","    3. Key products or services\n","    4. Recent news or developments\n","\n","    After gathering this information, use the write_document tool to save your findings in a file named 'CompanyResearchAlpha.txt'.\n","    Your response should include confirmation that the file was saved.\"\"\"\n",")\n","\n","# Add this to your node_functions dictionary\n","node_functions[\"CompanyResearchAlpha\"] = company_research_alpha"]},{"cell_type":"markdown","metadata":{},"source":["Defining Agent Nodes"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["# Define agent nodes\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    [tavily_tool, read_document, write_document, upload_document, query_vector_db],\n","    \"You are a company research specialist. Your task is to gather initial information about a target company. \"\n","    \"Ask the user for the company name or to upload a document with company info. \"\n","    \"Create initial documents for company name, description, execs, priorities, and industry priorities.\"\n",")\n","\n","# Company Description Team\n","company_description_research = create_agent_node(\n","    \"CompanyDescriptionResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a company description researcher. Your task is to find and compile a comprehensive description of the company.\"\n",")\n","\n","company_description_writing = create_agent_node(\n","    \"CompanyDescriptionWriting\",\n","    [read_document, write_document],\n","    \"You are a professional writer specializing in company descriptions. Your task is to take the research and craft a well-written company description.\"\n",")\n","\n","company_description_fact_checker = create_agent_node(\n","    \"CompanyDescriptionFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the company description.\"\n",")\n","\n","company_description_copy_editor = create_agent_node(\n","    \"CompanyDescriptionCopyEditor\",\n","    [read_document, write_document],\n","    \"\"\"You are a copy editor. Your task is to ensure the company description has correct grammar, spelling, and tone.\n","    Read the existing company description, make necessary edits, and save the improved version.\n","    If you encounter any issues with the input, please provide a clear explanation and save it in the output file.\"\"\"\n",")\n","\n","# Company Execs Team\n","company_execs_research = create_agent_node(\n","    \"CompanyExecsResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are an executive research specialist. Your task is to find the top 5 C-level executives of the company.\"\n",")\n","\n","company_execs_linkedin_check = create_agent_node(\n","    \"CompanyExecsLinkedInCheck\",\n","    [linkedin_check, read_document, write_document],\n","    \"You are a LinkedIn verification specialist. Your task is to verify if the executives are currently working at the company.\"\n",")\n","\n","company_execs_editor = create_agent_node(\n","    \"CompanyExecsEditor\",\n","    [read_document, write_document],\n","    \"You are an editor. Your task is to finalize the list of company executives, excluding any that are not currently with the company.\"\n",")\n","\n","# Company Priorities Team\n","company_priorities_research = create_agent_node(\n","    \"CompanyPrioritiesResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a company priorities researcher. Your task is to identify the top 3 priorities of the company.\"\n",")\n","\n","company_priorities_fact_checker = create_agent_node(\n","    \"CompanyPrioritiesFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the identified company priorities.\"\n",")\n","\n","company_priorities_copy_editor = create_agent_node(\n","    \"CompanyPrioritiesCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the company priorities are clearly and correctly stated.\"\n",")\n","\n","# Industry Trends Team\n","industry_trends_research = create_agent_node(\n","    \"IndustryTrendsResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are an industry trends researcher. Your task is to identify the industry of the company and its top trends and challenges.\"\n",")\n","\n","industry_trends_fact_checker = create_agent_node(\n","    \"IndustryTrendsFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the identified industry trends and challenges.\"\n",")\n","\n","industry_trends_copy_editor = create_agent_node(\n","    \"IndustryTrendsCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the industry trends and challenges are clearly and correctly stated.\"\n",")\n","\n","# Sales Pitch Team\n","value_proposition_research = create_agent_node(\n","    \"ValuePropositionResearch\",\n","    [tavily_tool, read_document, write_document, upload_document, query_vector_db],\n","    \"You are a value proposition researcher. Your task is to research and outline the value proposition of the user's company.\"\n",")\n","\n","value_proposition_fact_checker = create_agent_node(\n","    \"ValuePropositionFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the value proposition.\"\n",")\n","\n","value_proposition_copy_editor = create_agent_node(\n","    \"ValuePropositionCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the value proposition is clearly and correctly stated.\"\n",")\n","\n","sales_pitch_creator = create_agent_node(\n","    \"SalesPitchCreator\",\n","    [read_document, write_document, query_vector_db],\n","    \"\"\"You are a sales pitch creator. Your task is to create a compelling sales pitch based on the target company's information and the user's company value proposition.\n","    After creating the pitch, you MUST use the write_document tool to save it as 'final_sales_pitch.txt'.\n","    Your response should include the content of the sales pitch and confirmation that it was saved.\"\"\"\n",")\n","\n","sales_pitch_fact_checker = create_agent_node(\n","    \"SalesPitchFactChecker\",\n","    [read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the sales pitch.\"\n",")\n","\n","sales_pitch_copy_editor = create_agent_node(\n","    \"SalesPitchCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the sales pitch has correct grammar, spelling, and tone.\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Graph Creation"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["from typing import Dict, List, TypedDict\n","from langgraph.graph import StateGraph, END\n","from langchain_core.messages import HumanMessage\n","\n","# Define the state\n","class State(TypedDict):\n","    messages: List[HumanMessage]\n","    next: str\n","\n","# Create the graph\n","graph = StateGraph(State)\n","\n","# Define a dictionary mapping node names to their corresponding functions\n","node_functions = {\n","    \"CompanyResearchAlpha\": company_research_alpha,\n","    \"CompanyDescriptionResearch\": company_description_research,\n","    \"CompanyDescriptionWriting\": company_description_writing,\n","    \"CompanyDescriptionFactChecker\": company_description_fact_checker,\n","    \"CompanyDescriptionCopyEditor\": company_description_copy_editor,\n","    \"CompanyExecsResearch\": company_execs_research,\n","    \"CompanyExecsLinkedInCheck\": company_execs_linkedin_check,\n","    \"CompanyExecsEditor\": company_execs_editor,\n","    \"CompanyPrioritiesResearch\": company_priorities_research,\n","    \"CompanyPrioritiesFactChecker\": company_priorities_fact_checker,\n","    \"CompanyPrioritiesCopyEditor\": company_priorities_copy_editor,\n","    \"IndustryTrendsResearch\": industry_trends_research,\n","    \"IndustryTrendsFactChecker\": industry_trends_fact_checker,\n","    \"IndustryTrendsCopyEditor\": industry_trends_copy_editor,\n","    \"ValuePropositionResearch\": value_proposition_research,\n","    \"ValuePropositionFactChecker\": value_proposition_fact_checker,\n","    \"ValuePropositionCopyEditor\": value_proposition_copy_editor,\n","    \"SalesPitchCreator\": sales_pitch_creator,\n","    \"SalesPitchFactChecker\": sales_pitch_fact_checker,\n","    \"SalesPitchCopyEditor\": sales_pitch_copy_editor\n","}\n","\n","# Define the node order\n","node_order = [\n","    \"CompanyResearchAlpha\",\n","    \"CompanyDescriptionResearch\",\n","    \"CompanyDescriptionWriting\",\n","    \"CompanyDescriptionFactChecker\",\n","    \"CompanyDescriptionCopyEditor\",\n","    \"CompanyExecsResearch\",\n","    \"CompanyExecsLinkedInCheck\",\n","    \"CompanyExecsEditor\",\n","    \"CompanyPrioritiesResearch\",\n","    \"CompanyPrioritiesFactChecker\",\n","    \"CompanyPrioritiesCopyEditor\",\n","    \"IndustryTrendsResearch\",\n","    \"IndustryTrendsFactChecker\",\n","    \"IndustryTrendsCopyEditor\",\n","    \"ValuePropositionResearch\",\n","    \"ValuePropositionFactChecker\",\n","    \"ValuePropositionCopyEditor\",\n","    \"SalesPitchCreator\",\n","    \"SalesPitchFactChecker\",\n","    \"SalesPitchCopyEditor\"\n","]\n","\n","# Add nodes to the graph\n","for node in node_order:\n","    graph.add_node(node, node_functions[node])\n","\n","# Add edges between nodes\n","for i in range(len(node_order) - 1):\n","    current_node = node_order[i]\n","    next_node = node_order[i + 1]\n","    graph.add_edge(current_node, next_node)\n","\n","# Add conditional edges for each node\n","for i, node in enumerate(node_order):\n","    next_nodes = {next_node: next_node for next_node in node_order[i+1:]}\n","    next_nodes[\"END\"] = END\n","    \n","    graph.add_conditional_edges(\n","        node,\n","        lambda x: x[\"next\"],\n","        next_nodes\n","    )\n","\n","# Set the entry point\n","graph.set_entry_point(\"CompanyResearchAlpha\")\n","\n","# Compile the graph\n","workflow = graph.compile()"]},{"cell_type":"markdown","metadata":{},"source":["Sales Pitch Generator Function"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-03 15:49:36,132 - INFO - Executing step 1/5: CompanyResearchAlpha\n","2024-09-03 15:49:36,132 - DEBUG - Executing agent: CompanyResearchAlpha\n","2024-09-03 15:49:36,132 - DEBUG - Input state: {'messages': [HumanMessage(content='Generate a sales pitch for Amazon. Our company website is example.com.')], 'next': 'CompanyResearchAlpha', 'documents': {}}\n","2024-09-03 15:49:36,140 - ERROR - Error in agent execution: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'output_file', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-03 15:49:40,142 - DEBUG - Executing agent: CompanyResearchAlpha\n","2024-09-03 15:49:40,143 - DEBUG - Input state: {'messages': [HumanMessage(content='Generate a sales pitch for Amazon. Our company website is example.com.'), HumanMessage(content='Context from previous steps:\\n\\n\\nPlease continue the task based on this information.')], 'next': 'CompanyResearchAlpha', 'documents': {}, 'output_file': 'CompanyResearchAlpha.txt'}\n","2024-09-03 15:49:40,154 - ERROR - Error in agent execution: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'output_file', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-03 15:49:44,159 - DEBUG - Executing agent: CompanyResearchAlpha\n","2024-09-03 15:49:44,160 - DEBUG - Input state: {'messages': [HumanMessage(content='Generate a sales pitch for Amazon. Our company website is example.com.'), HumanMessage(content='Context from previous steps:\\n\\n\\nPlease continue the task based on this information.'), HumanMessage(content='Context from previous steps:\\n\\n\\nPlease continue the task based on this information.')], 'next': 'CompanyResearchAlpha', 'documents': {}, 'output_file': 'CompanyResearchAlpha.txt'}\n","2024-09-03 15:49:44,168 - ERROR - Error in agent execution: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'output_file', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-03 15:49:44,169 - ERROR - Error in CompanyResearchAlpha after retries: RetryError[<Future at 0x13f1c77d0 state=finished raised KeyError>]\n","2024-09-03 15:49:44,169 - DEBUG - State after CompanyResearchAlpha:\n","2024-09-03 15:49:44,169 - DEBUG - {\n","  \"messages\": [\n","    \"content='Generate a sales pitch for Amazon. Our company website is example.com.'\",\n","    \"content='Context from previous steps:\\\\n\\\\n\\\\nPlease continue the task based on this information.'\",\n","    \"content='Context from previous steps:\\\\n\\\\n\\\\nPlease continue the task based on this information.'\",\n","    \"content='Context from previous steps:\\\\n\\\\n\\\\nPlease continue the task based on this information.'\",\n","    \"content='Error in CompanyResearchAlpha: RetryError[<Future at 0x13f1c77d0 state=finished raised KeyError>]'\"\n","  ],\n","  \"next\": \"END\",\n","  \"documents\": {\n","    \"CompanyResearchAlpha\": \"Error: RetryError[<Future at 0x13f1c77d0 state=finished raised KeyError>]\"\n","  },\n","  \"last_output_file\": null\n","}\n","2024-09-03 15:49:44,169 - WARNING - Process ended early at step 1 (CompanyResearchAlpha)\n","2024-09-03 15:49:44,171 - INFO - Final sales pitch saved successfully.\n"]},{"name":"stdout","output_type":"stream","text":["Final Sales Pitch for Amazon\n","\n","Company Overview:\n","Error: RetryError[<Future at 0x13f1c77d0 state=finished raised KeyError>]\n","\n","Key Executives: Information not available.\n","\n","Company Priorities: Information not available.\n","\n","Value Proposition: Information not available.\n","\n","Final Pitch: Information not available.\n","\n","\n"]}],"source":["def run_sales_pitch_generator(target_company: str, user_company_url: str, debug: bool = False):\n","    if debug:\n","        logging.getLogger().setLevel(logging.DEBUG)\n","    \n","    initial_message = f\"Generate a sales pitch for {target_company}. Our company website is {user_company_url}.\"\n","    \n","    state = {\"messages\": [HumanMessage(content=initial_message)], \"next\": \"CompanyResearchAlpha\", \"documents\": {}}\n","    \n","    for step, node_name in enumerate(node_order):\n","        logging.info(f\"Executing step {step + 1}/{len(node_order)}: {node_name}\")\n","        \n","        if node_name not in node_functions:\n","            logging.error(f\"Node '{node_name}' not found in node_functions dictionary\")\n","            continue\n","        \n","        node_function = node_functions[node_name]\n","        try:\n","            new_state = node_function(state)\n","            logging.debug(f\"State after {node_name}:\")\n","            logging.debug(json.dumps(new_state, default=str, indent=2))\n","        except Exception as e:\n","            logging.error(f\"Error in {node_name}: {str(e)}\")\n","            new_state = {\n","                \"messages\": state[\"messages\"] + [AIMessage(content=f\"Error in {node_name}: {str(e)}\")],\n","                \"next\": \"END\",\n","                \"documents\": {**state.get(\"documents\", {}), node_name: f\"Error: {str(e)}\"},\n","                \"last_output_file\": None\n","            }\n","        \n","        state = new_state\n","        \n","        if state['next'] == \"END\":\n","            logging.warning(f\"Process ended early at step {step + 1} ({node_name})\")\n","            break\n","\n","    # After the chain completes, compile all the information into a final sales pitch\n","    final_pitch = compile_final_sales_pitch(state['documents'], target_company)\n","    \n","    # Save the final pitch\n","    final_pitch_path = WORKING_DIRECTORY / \"final_sales_pitch.txt\"\n","    try:\n","        with final_pitch_path.open(\"w\") as file:\n","            file.write(final_pitch)\n","        logging.info(\"Final sales pitch saved successfully.\")\n","    except IOError as e:\n","        logging.error(f\"Error saving final sales pitch: {e}\")\n","    \n","    return final_pitch\n","\n","def compile_final_sales_pitch(documents: Dict[str, str], target_company: str) -> str:\n","    pitch = f\"Final Sales Pitch for {target_company}\\n\\n\"\n","    \n","    sections = [\n","        (\"CompanyResearchAlpha\", \"Company Overview\"),\n","        (\"CompanyExecsEditor\", \"Key Executives\"),\n","        (\"CompanyPrioritiesCopyEditor\", \"Company Priorities\"),\n","        (\"ValuePropositionCopyEditor\", \"Value Proposition\"),\n","        (\"SalesPitchCopyEditor\", \"Final Pitch\")\n","    ]\n","    \n","    for doc_name, section_title in sections:\n","        content = documents.get(doc_name, \"\")\n","        if content.startswith(\"Error:\"):\n","            pitch += f\"{section_title}:\\n{content}\\n\\n\"\n","        elif content:\n","            pitch += f\"{section_title}:\\n{content[:500]}...\\n\\n\"\n","        else:\n","            pitch += f\"{section_title}: Information not available.\\n\\n\"\n","    \n","    if all(doc_name not in documents for doc_name, _ in sections):\n","        pitch += \"Error: No information was successfully generated for the sales pitch.\"\n","    \n","    return pitch\n","\n","# Make sure to define node_order and node_functions before using them in run_sales_pitch_generator\n","node_order = [\"CompanyResearchAlpha\", \"CompanyDescriptionResearch\", \"CompanyDescriptionWriting\", \"CompanyDescriptionFactChecker\", \"CompanyDescriptionCopyEditor\"]  # Add all your node names here\n","node_functions = {}  # This dictionary should be populated with your node functions\n","\n","# Example of adding a node function:\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    [write_document],  # Add other necessary tools\n","    \"\"\"You are a company research specialist. Your task is to gather initial information about the target company.\n","    Use the available tools to research the company and compile a brief summary including:\n","    1. Company name and basic description\n","    2. Industry\n","    3. Key products or services\n","    4. Recent news or developments\n","\n","    After gathering this information, use the write_document tool to save your findings.\"\"\"\n",")\n","node_functions[\"CompanyResearchAlpha\"] = company_research_alpha\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Main Chain and Execution"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-03 15:49:56,070 - INFO - Initializing vector store...\n","/var/folders/jr/_qkyxp313390z32jmym7j9sm0000gp/T/ipykernel_64437/553466154.py:2: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n","  qdrant_client.recreate_collection(\n","2024-09-03 15:50:03,048 - INFO - Generating sales pitch for Amazon...\n","2024-09-03 15:50:03,049 - INFO - Executing step 1/5: CompanyResearchAlpha\n","2024-09-03 15:50:03,049 - DEBUG - Executing agent: CompanyResearchAlpha\n","2024-09-03 15:50:03,049 - DEBUG - Input state: {'messages': [HumanMessage(content='Generate a sales pitch for Amazon. Our company website is www.snowflake.com.')], 'next': 'CompanyResearchAlpha', 'documents': {}}\n","2024-09-03 15:50:03,060 - ERROR - Error in agent execution: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'output_file', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-03 15:50:07,065 - DEBUG - Executing agent: CompanyResearchAlpha\n","2024-09-03 15:50:07,066 - DEBUG - Input state: {'messages': [HumanMessage(content='Generate a sales pitch for Amazon. Our company website is www.snowflake.com.'), HumanMessage(content='Context from previous steps:\\n\\n\\nPlease continue the task based on this information.')], 'next': 'CompanyResearchAlpha', 'documents': {}, 'output_file': 'CompanyResearchAlpha.txt'}\n","2024-09-03 15:50:07,077 - ERROR - Error in agent execution: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'output_file', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-03 15:50:11,080 - DEBUG - Executing agent: CompanyResearchAlpha\n","2024-09-03 15:50:11,081 - DEBUG - Input state: {'messages': [HumanMessage(content='Generate a sales pitch for Amazon. Our company website is www.snowflake.com.'), HumanMessage(content='Context from previous steps:\\n\\n\\nPlease continue the task based on this information.'), HumanMessage(content='Context from previous steps:\\n\\n\\nPlease continue the task based on this information.')], 'next': 'CompanyResearchAlpha', 'documents': {}, 'output_file': 'CompanyResearchAlpha.txt'}\n","2024-09-03 15:50:11,088 - ERROR - Error in agent execution: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'output_file', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-03 15:50:11,089 - ERROR - Error in CompanyResearchAlpha after retries: RetryError[<Future at 0x14fc58b10 state=finished raised KeyError>]\n","2024-09-03 15:50:11,089 - DEBUG - State after CompanyResearchAlpha:\n","2024-09-03 15:50:11,090 - DEBUG - {\n","  \"messages\": [\n","    \"content='Generate a sales pitch for Amazon. Our company website is www.snowflake.com.'\",\n","    \"content='Context from previous steps:\\\\n\\\\n\\\\nPlease continue the task based on this information.'\",\n","    \"content='Context from previous steps:\\\\n\\\\n\\\\nPlease continue the task based on this information.'\",\n","    \"content='Context from previous steps:\\\\n\\\\n\\\\nPlease continue the task based on this information.'\",\n","    \"content='Error in CompanyResearchAlpha: RetryError[<Future at 0x14fc58b10 state=finished raised KeyError>]'\"\n","  ],\n","  \"next\": \"END\",\n","  \"documents\": {\n","    \"CompanyResearchAlpha\": \"Error: RetryError[<Future at 0x14fc58b10 state=finished raised KeyError>]\"\n","  },\n","  \"last_output_file\": null\n","}\n","2024-09-03 15:50:11,090 - WARNING - Process ended early at step 1 (CompanyResearchAlpha)\n","2024-09-03 15:50:11,091 - INFO - Final sales pitch saved successfully.\n","2024-09-03 15:50:11,091 - INFO - \n","Final Sales Pitch:\n","2024-09-03 15:50:11,091 - WARNING - File CompanyResearchAlpha.txt was not created during the process\n","2024-09-03 15:50:11,092 - WARNING - File CompanyDescriptionResearch.txt was not created during the process\n","2024-09-03 15:50:11,092 - WARNING - File CompanyDescriptionWriting.txt was not created during the process\n","2024-09-03 15:50:11,093 - WARNING - File CompanyDescriptionFactChecker.txt was not created during the process\n","2024-09-03 15:50:11,093 - WARNING - File CompanyDescriptionCopyEditor.txt was not created during the process\n","2024-09-03 15:50:11,094 - INFO - Cleaning up temporary files...\n","2024-09-03 15:50:11,094 - WARNING - File CompanyResearchAlpha.txt not found during cleanup\n","2024-09-03 15:50:11,094 - WARNING - File CompanyDescriptionResearch.txt not found during cleanup\n","2024-09-03 15:50:11,095 - WARNING - File CompanyDescriptionWriting.txt not found during cleanup\n","2024-09-03 15:50:11,095 - WARNING - File CompanyDescriptionFactChecker.txt not found during cleanup\n","2024-09-03 15:50:11,095 - WARNING - File CompanyDescriptionCopyEditor.txt not found during cleanup\n","2024-09-03 15:50:11,096 - INFO - Process completed.\n","2024-09-03 15:50:11,096 - DEBUG - Starting execution of node: CompanyResearchAlpha\n","2024-09-03 15:50:11,097 - DEBUG - Starting execution of node: CompanyDescriptionResearch\n","2024-09-03 15:50:11,097 - DEBUG - Starting execution of node: CompanyDescriptionWriting\n","2024-09-03 15:50:11,097 - DEBUG - Starting execution of node: CompanyDescriptionFactChecker\n","2024-09-03 15:50:11,098 - DEBUG - Starting execution of node: CompanyDescriptionCopyEditor\n"]},{"name":"stdout","output_type":"stream","text":["Final Sales Pitch for Amazon\n","\n","Company Overview:\n","Error: RetryError[<Future at 0x14fc58b10 state=finished raised KeyError>]\n","\n","Key Executives: Information not available.\n","\n","Company Priorities: Information not available.\n","\n","Value Proposition: Information not available.\n","\n","Final Pitch: Information not available.\n","\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    try:\n","        logging.info(\"Initializing vector store...\")\n","        initialize_vector_store()\n","        \n","        target_company = input(\"Enter the name of the company you want to prospect: \").strip()\n","        user_company_url = input(\"Enter your company's URL so we can understand your value proposition: \").strip()\n","        \n","        logging.info(f\"Generating sales pitch for {target_company}...\")\n","        final_pitch = run_sales_pitch_generator(target_company, user_company_url)\n","        \n","        logging.info(\"\\nFinal Sales Pitch:\")\n","        print(final_pitch)\n","        \n","        # Print contents of all generated files\n","        for node_name in node_order:\n","            file_name = f\"{node_name}.txt\"\n","            file_path = WORKING_DIRECTORY / file_name\n","            if file_path.exists():\n","                try:\n","                    with file_path.open(\"r\") as file:\n","                        content = file.read().strip()\n","                        logging.info(f\"\\nContents of {file_name}:\\n{content[:500]}...\\n---\")\n","                except IOError as e:\n","                    logging.error(f\"Error reading {file_name}: {e}\")\n","            else:\n","                logging.warning(f\"File {file_name} was not created during the process\")\n","        \n","    except Exception as e:\n","        logging.error(f\"An unexpected error occurred: {e}\")\n","        logging.exception(\"Detailed traceback:\")\n","    \n","    finally:\n","        logging.info(\"Cleaning up temporary files...\")\n","        for node_name in node_order:\n","            file_name = f\"{node_name}.txt\"\n","            file_path = WORKING_DIRECTORY / file_name\n","            try:\n","                file_path.unlink()\n","                logging.info(f\"Deleted {file_name}\")\n","            except FileNotFoundError:\n","                logging.warning(f\"File {file_name} not found during cleanup\")\n","        \n","        logging.info(\"Process completed.\")"]}],"metadata":{"kernelspec":{"display_name":"llmops-course","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}

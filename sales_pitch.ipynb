{"cells":[{"cell_type":"markdown","metadata":{},"source":["Installing libraries"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -qU langgraph langchain langchain_openai langchain_community qdrant-client PyPDF2 beautifulsoup4 requests"]},{"cell_type":"markdown","metadata":{},"source":["Setting up imports"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["import os\n","import getpass\n","from typing import List, Dict, Any, Union, Annotated, Optional\n","from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.agents import AgentExecutor, create_openai_functions_agent\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.tools import BaseTool, tool\n","from langgraph.graph import StateGraph, END\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_community.vectorstores import Qdrant\n","import functools\n","import operator\n","from pathlib import Path\n","import uuid\n","import requests\n","from bs4 import BeautifulSoup\n","import PyPDF2\n","import io\n","from qdrant_client import QdrantClient\n","from qdrant_client.http import models as rest\n","\n","# Set up API keys\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n","os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a working directory"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","WORKING_DIRECTORY = Path(\"./content/data\")\n","WORKING_DIRECTORY.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize Qdrant Client and OpenAI Embeddings"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# Initialize Qdrant client\n","qdrant_client = QdrantClient(\":memory:\")  # Use in-memory storage for simplicity\n","\n","# Initialize OpenAI embeddings\n","embeddings = OpenAIEmbeddings()"]},{"cell_type":"markdown","metadata":{},"source":["State and Helper functions"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["class State(Dict[str, Any]):\n","    messages: Annotated[List[BaseMessage], operator.add]\n","    next: str\n","    documents: Dict[str, str]\n","\n","def get_last_message(state: State) -> str:\n","    return state[\"messages\"][-1].content\n","\n","def join_graph(response: dict):\n","    return {\"messages\": [response[\"messages\"][-1]]}\n","\n","def prelude(state):\n","    written_files = []\n","    try:\n","        written_files = [f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.glob(\"*\")]\n","    except:\n","        pass\n","    if not written_files:\n","        return {**state, \"current_files\": \"No files written.\"}\n","    return {\n","        **state,\n","        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n","        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["Setting up Vector Store"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["def initialize_vector_store():\n","    qdrant_client.recreate_collection(\n","        collection_name=\"sales_pitch_data\",\n","        vectors_config=rest.VectorParams(size=1536, distance=rest.Distance.COSINE),\n","    )\n","\n","def add_to_vector_store(text: str, metadata: Dict[str, Any]):\n","    vector = embeddings.embed_query(text)\n","    qdrant_client.upsert(\n","        collection_name=\"sales_pitch_data\",\n","        points=[rest.PointStruct(id=uuid.uuid4().hex, vector=vector, payload=metadata)],\n","    )\n","\n","def query_vector_store(query: str, limit: int = 5) -> List[Dict[str, Any]]:\n","    query_vector = embeddings.embed_query(query)\n","    search_result = qdrant_client.search(\n","        collection_name=\"sales_pitch_data\",\n","        query_vector=query_vector,\n","        limit=limit,\n","    )\n","    return [hit.payload for hit in search_result]"]},{"cell_type":"markdown","metadata":{},"source":["Tools"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["tavily_tool = TavilySearchResults(max_results=5)\n","\n","@tool\n","def linkedin_check(name: str, company: str) -> bool:\n","    \"\"\"Check if a person works at a specific company on LinkedIn.\"\"\"\n","    # Note: This is a mock implementation. In a real scenario, you'd use LinkedIn's API or web scraping.\n","    url = f\"https://www.linkedin.com/search/results/people/?keywords={name} {company}\"\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    return company.lower() in soup.text.lower()\n","\n","@tool\n","def read_document(\n","    file_name: Annotated[str, \"File path to read the document.\"],\n","    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n","    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",") -> str:\n","    \"\"\"Read the specified document.\"\"\"\n","    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n","        lines = file.readlines()\n","    if start is None:\n","        start = 0\n","    return \"\".join(lines[start:end])\n","\n","import os\n","\n","import os\n","\n","@tool\n","def write_document(\n","    content: Annotated[str, \"Text content to be written into the document.\"],\n","    state: Annotated[dict, \"The current state of the conversation.\"],\n",") -> Annotated[str, \"Path of the saved document file or error message.\"]:\n","    \"\"\"Create and save a text document.\"\"\"\n","    file_name = state.get(\"output_file\", \"output.txt\")\n","    file_path = WORKING_DIRECTORY / file_name\n","    logging.info(f\"Attempting to write document: {file_path}\")\n","    try:\n","        logging.debug(f\"Content to write: {content[:100]}...\")  # Log first 100 chars\n","        \n","        # Ensure the directory exists\n","        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","        \n","        with file_path.open(\"w\") as file:\n","            file.write(content)\n","        logging.info(f\"Successfully wrote content to {file_path}\")\n","        return f\"Document saved to {file_path}\"\n","    except IOError as e:\n","        error_msg = f\"IOError writing to {file_path}: {e}\"\n","        logging.error(error_msg)\n","        return error_msg\n","    except Exception as e:\n","        error_msg = f\"Unexpected error writing to {file_path}: {e}\"\n","        logging.error(error_msg)\n","        return error_msg\n","\n","@tool\n","def upload_document(file_path: str) -> str:\n","    \"\"\"Upload and read a document (PDF or text).\"\"\"\n","    file_extension = Path(file_path).suffix.lower()\n","    if file_extension == '.pdf':\n","        with open(file_path, 'rb') as file:\n","            pdf_reader = PyPDF2.PdfReader(file)\n","            text = \"\"\n","            for page in pdf_reader.pages:\n","                text += page.extract_text()\n","    elif file_extension in ['.txt', '.md']:\n","        with open(file_path, 'r') as file:\n","            text = file.read()\n","    else:\n","        raise ValueError(\"Unsupported file type. Please upload a PDF or text file.\")\n","    \n","    # Save the extracted text to a file in the working directory\n","    output_file = WORKING_DIRECTORY / f\"uploaded_document_{uuid.uuid4()}.txt\"\n","    with output_file.open(\"w\") as file:\n","        file.write(text)\n","    \n","    return f\"Document uploaded and saved as {output_file.name}\"\n","\n","@tool\n","def query_vector_db(query: str) -> str:\n","    \"\"\"Query the vector database for relevant information.\"\"\"\n","    results = query_vector_store(query)\n","    return \"\\n\".join([f\"{item['type']}: {item['content']}\" for item in results])"]},{"cell_type":"markdown","metadata":{},"source":["Agent Creation"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["from tenacity import retry, stop_after_attempt, wait_exponential\n","\n","def create_agent_node(name: str, tools: List[BaseTool], system_prompt: str):\n","    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n","    prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", system_prompt + \"\\n\\nAfter completing your task, you MUST use the write_document tool to save your output. Use the following format:\\n\\nThought: I will now save my findings using the write_document tool.\\nAction: write_document\\nAction Input: {{\\n  \\\"content\\\": \\\"Your detailed findings here\\\",\\n  \\\"state\\\": {{\\n    \\\"output_file\\\": \\\"{name}.txt\\\"\\n  }}\\n}}\\nObservation: The result of using the write_document tool.\\nThought: I have saved my findings. I will now summarize what I did.\\nHuman: Great, please summarize what you did and confirm that you saved the document.\"),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ])\n","    agent = create_openai_functions_agent(llm, tools, prompt)\n","    agent_executor = AgentExecutor(agent=agent, tools=tools)\n","\n","    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n","    def execute_agent_with_retry(state):\n","        logging.debug(f\"Executing agent: {name}\")\n","        logging.debug(f\"Input state: {state}\")\n","        \n","        # Add the output_file to the state\n","        state[\"output_file\"] = f\"{name}.txt\"\n","        \n","        # Add context from previous steps\n","        context = \"\\n\".join([f\"{k}: {v[:500]}...\" for k, v in state.get('documents', {}).items()])\n","        state[\"messages\"].append(HumanMessage(content=f\"Context from previous steps:\\n{context}\\n\\nPlease continue the task based on this information.\"))\n","        \n","        result = agent_executor.invoke(state)\n","        logging.debug(f\"Agent result: {result}\")\n","        \n","        # Check if the expected file was created\n","        expected_file = WORKING_DIRECTORY / state[\"output_file\"]\n","        if not expected_file.exists():\n","            logging.error(f\"Expected file {expected_file} was not created by {name}\")\n","            # Fallback: Use the agent's output as content\n","            content = result.get(\"output\", f\"Error: No output generated by {name}\")\n","            logging.warning(f\"Using agent output as fallback content for {name}\")\n","        else:\n","            with expected_file.open(\"r\") as file:\n","                content = file.read().strip()\n","        \n","        return content, result\n","    \n"," \n","    def execute_agent(state):\n","        try:\n","            content, result = execute_agent_with_retry(state)\n","            \n","            new_state = {\n","                \"messages\": state[\"messages\"] + [AIMessage(content=content)],\n","                \"next\": name,  # Default to current node if not specified\n","                \"documents\": {**state.get(\"documents\", {}), name: content},\n","                \"last_output_file\": state[\"output_file\"]\n","            }\n","            \n","            logging.debug(f\"Output state: {new_state}\")\n","            return new_state\n","        \n","        except Exception as e:\n","            logging.error(f\"Error in {name} after retries: {str(e)}\")\n","            # Return a partial state with error information\n","            return {\n","                \"messages\": state[\"messages\"] + [AIMessage(content=f\"Error in {name}: {str(e)}\")],\n","                \"next\": \"END\",\n","                \"documents\": {**state.get(\"documents\", {}), name: f\"Error: {str(e)}\"},\n","                \"last_output_file\": None\n","            }\n","    \n","    return execute_agent"]},{"cell_type":"markdown","metadata":{},"source":["ComplanyResearchAlpha Function Definition"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["# Define the tools that CompanyResearchAlpha will use\n","company_research_tools = [\n","    tavily_tool,\n","    read_document,\n","    write_document,\n","    upload_document,\n","    query_vector_db\n","]\n","\n","# Create the CompanyResearchAlpha node\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    company_research_tools,\n","    \"\"\"You are a company research specialist. Your task is to gather initial information about the target company.\n","    Use the available tools to research the company and compile a brief summary including:\n","    1. Company name and basic description\n","    2. Industry\n","    3. Key products or services\n","    4. Recent news or developments\n","\n","    After gathering this information, use the write_document tool to save your findings in a file named 'CompanyResearchAlpha.txt'.\n","    Your response should include confirmation that the file was saved.\"\"\"\n",")\n","\n","# Add this to your node_functions dictionary\n","node_functions[\"CompanyResearchAlpha\"] = company_research_alpha"]},{"cell_type":"markdown","metadata":{},"source":["Defining Agent Nodes"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["# Define agent nodes\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    [tavily_tool, read_document, write_document, upload_document, query_vector_db],\n","    \"You are a company research specialist. Your task is to gather initial information about a target company. \"\n","    \"Ask the user for the company name or to upload a document with company info. \"\n","    \"Create initial documents for company name, description, execs, priorities, and industry priorities.\"\n",")\n","\n","# Company Description Team\n","company_description_research = create_agent_node(\n","    \"CompanyDescriptionResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a company description researcher. Your task is to find and compile a comprehensive description of the company.\"\n",")\n","\n","company_description_writing = create_agent_node(\n","    \"CompanyDescriptionWriting\",\n","    [read_document, write_document],\n","    \"You are a professional writer specializing in company descriptions. Your task is to take the research and craft a well-written company description.\"\n",")\n","\n","company_description_fact_checker = create_agent_node(\n","    \"CompanyDescriptionFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the company description.\"\n",")\n","\n","company_description_copy_editor = create_agent_node(\n","    \"CompanyDescriptionCopyEditor\",\n","    [read_document, write_document],\n","    \"\"\"You are a copy editor. Your task is to ensure the company description has correct grammar, spelling, and tone.\n","    Read the existing company description, make necessary edits, and save the improved version.\n","    If you encounter any issues with the input, please provide a clear explanation and save it in the output file.\"\"\"\n",")\n","\n","# Company Execs Team\n","company_execs_research = create_agent_node(\n","    \"CompanyExecsResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are an executive research specialist. Your task is to find the top 5 C-level executives of the company.\"\n",")\n","\n","company_execs_linkedin_check = create_agent_node(\n","    \"CompanyExecsLinkedInCheck\",\n","    [linkedin_check, read_document, write_document],\n","    \"You are a LinkedIn verification specialist. Your task is to verify if the executives are currently working at the company.\"\n",")\n","\n","company_execs_editor = create_agent_node(\n","    \"CompanyExecsEditor\",\n","    [read_document, write_document],\n","    \"You are an editor. Your task is to finalize the list of company executives, excluding any that are not currently with the company.\"\n",")\n","\n","# Company Priorities Team\n","company_priorities_research = create_agent_node(\n","    \"CompanyPrioritiesResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a company priorities researcher. Your task is to identify the top 3 priorities of the company.\"\n",")\n","\n","company_priorities_fact_checker = create_agent_node(\n","    \"CompanyPrioritiesFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the identified company priorities.\"\n",")\n","\n","company_priorities_copy_editor = create_agent_node(\n","    \"CompanyPrioritiesCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the company priorities are clearly and correctly stated.\"\n",")\n","\n","# Industry Trends Team\n","industry_trends_research = create_agent_node(\n","    \"IndustryTrendsResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are an industry trends researcher. Your task is to identify the industry of the company and its top trends and challenges.\"\n",")\n","\n","industry_trends_fact_checker = create_agent_node(\n","    \"IndustryTrendsFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the identified industry trends and challenges.\"\n",")\n","\n","industry_trends_copy_editor = create_agent_node(\n","    \"IndustryTrendsCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the industry trends and challenges are clearly and correctly stated.\"\n",")\n","\n","# Sales Pitch Team\n","value_proposition_research = create_agent_node(\n","    \"ValuePropositionResearch\",\n","    [tavily_tool, read_document, write_document, upload_document, query_vector_db],\n","    \"You are a value proposition researcher. Your task is to research and outline the value proposition of the user's company.\"\n",")\n","\n","value_proposition_fact_checker = create_agent_node(\n","    \"ValuePropositionFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the value proposition.\"\n",")\n","\n","value_proposition_copy_editor = create_agent_node(\n","    \"ValuePropositionCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the value proposition is clearly and correctly stated.\"\n",")\n","\n","sales_pitch_creator = create_agent_node(\n","    \"SalesPitchCreator\",\n","    [read_document, write_document, query_vector_db],\n","    \"\"\"You are a sales pitch creator. Your task is to create a compelling sales pitch based on the target company's information and the user's company value proposition.\n","    After creating the pitch, you MUST use the write_document tool to save it as 'final_sales_pitch.txt'.\n","    Your response should include the content of the sales pitch and confirmation that it was saved.\"\"\"\n",")\n","\n","sales_pitch_fact_checker = create_agent_node(\n","    \"SalesPitchFactChecker\",\n","    [read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the sales pitch.\"\n",")\n","\n","sales_pitch_copy_editor = create_agent_node(\n","    \"SalesPitchCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the sales pitch has correct grammar, spelling, and tone.\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Graph Creation"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["from typing import Dict, List, TypedDict\n","from langgraph.graph import StateGraph, END\n","from langchain_core.messages import HumanMessage\n","\n","# Define the state\n","class State(TypedDict):\n","    messages: List[HumanMessage]\n","    next: str\n","\n","# Create the graph\n","graph = StateGraph(State)\n","\n","# Define a dictionary mapping node names to their corresponding functions\n","node_functions = {\n","    \"CompanyResearchAlpha\": company_research_alpha,\n","    \"CompanyDescriptionResearch\": company_description_research,\n","    \"CompanyDescriptionWriting\": company_description_writing,\n","    \"CompanyDescriptionFactChecker\": company_description_fact_checker,\n","    \"CompanyDescriptionCopyEditor\": company_description_copy_editor,\n","    \"CompanyExecsResearch\": company_execs_research,\n","    \"CompanyExecsLinkedInCheck\": company_execs_linkedin_check,\n","    \"CompanyExecsEditor\": company_execs_editor,\n","    \"CompanyPrioritiesResearch\": company_priorities_research,\n","    \"CompanyPrioritiesFactChecker\": company_priorities_fact_checker,\n","    \"CompanyPrioritiesCopyEditor\": company_priorities_copy_editor,\n","    \"IndustryTrendsResearch\": industry_trends_research,\n","    \"IndustryTrendsFactChecker\": industry_trends_fact_checker,\n","    \"IndustryTrendsCopyEditor\": industry_trends_copy_editor,\n","    \"ValuePropositionResearch\": value_proposition_research,\n","    \"ValuePropositionFactChecker\": value_proposition_fact_checker,\n","    \"ValuePropositionCopyEditor\": value_proposition_copy_editor,\n","    \"SalesPitchCreator\": sales_pitch_creator,\n","    \"SalesPitchFactChecker\": sales_pitch_fact_checker,\n","    \"SalesPitchCopyEditor\": sales_pitch_copy_editor\n","}\n","\n","# Define the node order\n","node_order = [\n","    \"CompanyResearchAlpha\",\n","    \"CompanyDescriptionResearch\",\n","    \"CompanyDescriptionWriting\",\n","    \"CompanyDescriptionFactChecker\",\n","    \"CompanyDescriptionCopyEditor\",\n","    \"CompanyExecsResearch\",\n","    \"CompanyExecsLinkedInCheck\",\n","    \"CompanyExecsEditor\",\n","    \"CompanyPrioritiesResearch\",\n","    \"CompanyPrioritiesFactChecker\",\n","    \"CompanyPrioritiesCopyEditor\",\n","    \"IndustryTrendsResearch\",\n","    \"IndustryTrendsFactChecker\",\n","    \"IndustryTrendsCopyEditor\",\n","    \"ValuePropositionResearch\",\n","    \"ValuePropositionFactChecker\",\n","    \"ValuePropositionCopyEditor\",\n","    \"SalesPitchCreator\",\n","    \"SalesPitchFactChecker\",\n","    \"SalesPitchCopyEditor\"\n","]\n","\n","graph = StateGraph(State)\n","\n","# Add nodes to the graph\n","for node in node_order:\n","    graph.add_node(node, node_functions[node])\n","\n","# Add edges between nodes\n","for i in range(len(node_order) - 1):\n","    current_node = node_order[i]\n","    next_node = node_order[i + 1]\n","    graph.add_edge(current_node, next_node)\n","\n","# Add conditional edges for each node\n","for i, node in enumerate(node_order):\n","    next_nodes = {next_node: next_node for next_node in node_order[i+1:]}\n","    next_nodes[\"END\"] = END\n","    \n","    graph.add_conditional_edges(\n","        node,\n","        lambda x: x[\"next\"],\n","        next_nodes\n","    )\n","\n","# Set the entry point\n","graph.set_entry_point(\"CompanyResearchAlpha\")\n","\n","# Compile the graph\n","workflow = graph.compile()"]},{"cell_type":"markdown","metadata":{},"source":["Sales Pitch Generator Function"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["import json\n","import logging\n","from typing import List, Dict, Any, Union, Annotated\n","from pathlib import Path\n","from tenacity import retry, stop_after_attempt, wait_exponential\n","from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import AgentExecutor, create_openai_functions_agent\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.tools import BaseTool, tool\n","\n","# Ensure WORKING_DIRECTORY is defined\n","WORKING_DIRECTORY = Path(\"./content/data\")\n","WORKING_DIRECTORY.mkdir(parents=True, exist_ok=True)\n","\n","def create_agent_node(name: str, tools: List[BaseTool], system_prompt: str):\n","    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n","    prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", system_prompt + \"\\n\\nAfter completing your task, you MUST use the write_document tool to save your output. Use the following format:\\n\\nThought: I will now save my findings using the write_document tool.\\nAction: write_document\\nAction Input: {{\\n  \\\"content\\\": \\\"Your detailed findings here\\\",\\n  \\\"state\\\": {{\\n    \\\"output_file\\\": \\\"{name}.txt\\\"\\n  }}\\n}}\\nObservation: The result of using the write_document tool.\\nThought: I have saved my findings. I will now summarize what I did.\\nHuman: Great, please summarize what you did and confirm that you saved the document.\"),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ])\n","    agent = create_openai_functions_agent(llm, tools, prompt)\n","    agent_executor = AgentExecutor(agent=agent, tools=tools)\n","\n","    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n","    def execute_agent_with_retry(state):\n","        logging.debug(f\"Executing agent: {name}\")\n","        logging.debug(f\"Input state: {state}\")\n","        \n","        # Add the output_file to the state\n","        state[\"output_file\"] = f\"{name}.txt\"\n","        \n","        # Add context from previous steps\n","        context = \"\\n\".join([f\"{k}: {v[:500]}...\" for k, v in state.get('documents', {}).items()])\n","        state[\"messages\"].append(HumanMessage(content=f\"Context from previous steps:\\n{context}\\n\\nPlease continue the task based on this information.\"))\n","        \n","        try:\n","            result = agent_executor.invoke(state)\n","            logging.debug(f\"Agent result: {result}\")\n","        except Exception as e:\n","            logging.error(f\"Error in agent execution: {str(e)}\")\n","            raise\n","        \n","        # Check if the expected file was created\n","        expected_file = WORKING_DIRECTORY / state[\"output_file\"]\n","        if not expected_file.exists():\n","            logging.error(f\"Expected file {expected_file} was not created by {name}\")\n","            # Fallback: Use the agent's output as content\n","            content = result.get(\"output\", f\"Error: No output generated by {name}\")\n","            logging.warning(f\"Using agent output as fallback content for {name}\")\n","        else:\n","            with expected_file.open(\"r\") as file:\n","                content = file.read().strip()\n","        \n","        return content, result\n","    \n","    def execute_agent(state):\n","        try:\n","            content, result = execute_agent_with_retry(state)\n","            \n","            new_state = {\n","                \"messages\": state[\"messages\"] + [AIMessage(content=content)],\n","                \"next\": name,  # Default to current node if not specified\n","                \"documents\": {**state.get(\"documents\", {}), name: content},\n","                \"last_output_file\": state[\"output_file\"]\n","            }\n","            \n","            logging.debug(f\"Output state: {json.dumps(new_state, default=str, indent=2)}\")\n","            return new_state\n","        \n","        except Exception as e:\n","            logging.error(f\"Error in {name} after retries: {str(e)}\")\n","            # Return a partial state with error information\n","            return {\n","                \"messages\": state[\"messages\"] + [AIMessage(content=f\"Error in {name}: {str(e)}\")],\n","                \"next\": \"END\",\n","                \"documents\": {**state.get(\"documents\", {}), name: f\"Error: {str(e)}\"},\n","                \"last_output_file\": None\n","            }\n","    \n","    return execute_agent\n","\n","def run_sales_pitch_generator(target_company: str, user_company_url: str, debug: bool = False):\n","    if debug:\n","        logging.getLogger().setLevel(logging.DEBUG)\n","    \n","    initial_message = f\"Generate a sales pitch for {target_company}. Our company website is {user_company_url}.\"\n","    \n","    state = {\"messages\": [HumanMessage(content=initial_message)], \"next\": \"CompanyResearchAlpha\", \"documents\": {}}\n","    \n","    for step, node_name in enumerate(node_order):\n","        logging.info(f\"Executing step {step + 1}/{len(node_order)}: {node_name}\")\n","        \n","        if node_name not in node_functions:\n","            logging.error(f\"Node '{node_name}' not found in node_functions dictionary\")\n","            continue\n","        \n","        node_function = node_functions[node_name]\n","        try:\n","            new_state = node_function(state)\n","            logging.debug(f\"State after {node_name}:\")\n","            logging.debug(json.dumps(new_state, default=str, indent=2))\n","        except Exception as e:\n","            logging.error(f\"Error in {node_name}: {str(e)}\")\n","            new_state = {\n","                \"messages\": state[\"messages\"] + [AIMessage(content=f\"Error in {node_name}: {str(e)}\")],\n","                \"next\": \"END\",\n","                \"documents\": {**state.get(\"documents\", {}), node_name: f\"Error: {str(e)}\"},\n","                \"last_output_file\": None\n","            }\n","        \n","        state = new_state\n","        \n","        if state['next'] == \"END\":\n","            logging.warning(f\"Process ended early at step {step + 1} ({node_name})\")\n","            break\n","\n","    # After the chain completes, compile all the information into a final sales pitch\n","    final_pitch = compile_final_sales_pitch(state['documents'], target_company)\n","    \n","    # Save the final pitch\n","    final_pitch_path = WORKING_DIRECTORY / \"final_sales_pitch.txt\"\n","    try:\n","        with final_pitch_path.open(\"w\") as file:\n","            file.write(final_pitch)\n","        logging.info(\"Final sales pitch saved successfully.\")\n","    except IOError as e:\n","        logging.error(f\"Error saving final sales pitch: {e}\")\n","    \n","    return final_pitch\n","\n","def compile_final_sales_pitch(documents: Dict[str, str], target_company: str) -> str:\n","    pitch = f\"Final Sales Pitch for {target_company}\\n\\n\"\n","    \n","    sections = [\n","        (\"CompanyResearchAlpha\", \"Company Overview\"),\n","        (\"CompanyExecsEditor\", \"Key Executives\"),\n","        (\"CompanyPrioritiesCopyEditor\", \"Company Priorities\"),\n","        (\"ValuePropositionCopyEditor\", \"Value Proposition\"),\n","        (\"SalesPitchCopyEditor\", \"Final Pitch\")\n","    ]\n","    \n","    for doc_name, section_title in sections:\n","        content = documents.get(doc_name, \"\")\n","        if content.startswith(\"Error:\"):\n","            pitch += f\"{section_title}:\\n{content}\\n\\n\"\n","        elif content:\n","            pitch += f\"{section_title}:\\n{content[:500]}...\\n\\n\"\n","        else:\n","            pitch += f\"{section_title}: Information not available.\\n\\n\"\n","    \n","    if all(doc_name not in documents for doc_name, _ in sections):\n","        pitch += \"Error: No information was successfully generated for the sales pitch.\"\n","    \n","    return pitch\n","\n","# Make sure to define node_order and node_functions before using them in run_sales_pitch_generator\n","node_order = [\"CompanyResearchAlpha\", \"CompanyDescriptionResearch\", \"CompanyDescriptionWriting\", \"CompanyDescriptionFactChecker\", \"CompanyDescriptionCopyEditor\"]  # Add all your node names here\n","node_functions = {}  # This dictionary should be populated with your node functions\n","\n","# Example of adding a node function:\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    [write_document],  # Add other necessary tools\n","    \"\"\"You are a company research specialist. Your task is to gather initial information about the target company.\n","    Use the available tools to research the company and compile a brief summary including:\n","    1. Company name and basic description\n","    2. Industry\n","    3. Key products or services\n","    4. Recent news or developments\n","\n","    After gathering this information, use the write_document tool to save your findings.\"\"\"\n",")\n","node_functions[\"CompanyResearchAlpha\"] = company_research_alpha\n","\n","# Add other node functions similarly\n","\n","if __name__ == \"__main__\":\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","    target_company = \"Amazon\"\n","    user_company_url = \"example.com\"\n","    final_pitch = run_sales_pitch_generator(target_company, user_company_url, debug=True)\n","    print(final_pitch)"]},{"cell_type":"markdown","metadata":{},"source":["Main Chain and Execution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Main Code Execution Block\n","\n","if __name__ == \"__main__\":\n","    try:\n","        logging.info(\"Initializing vector store...\")\n","        initialize_vector_store()\n","        \n","        while True:\n","            target_company = input(\"Enter the name of the company you want to prospect: \").strip()\n","            if target_company:\n","                break\n","            print(\"Company name cannot be empty. Please try again.\")\n","        \n","        while True:\n","            user_company_url = input(\"Enter your company's URL so we can understand your value proposition: \").strip()\n","            if user_company_url and \".\" in user_company_url:\n","                break\n","            print(\"Please enter a valid URL.\")\n","        \n","        logging.info(f\"Generating sales pitch for {target_company}...\")\n","        final_pitch = run_sales_pitch_generator(target_company, user_company_url)\n","        \n","        logging.info(\"\\nFinal Sales Pitch:\")\n","        print(final_pitch)\n","        \n","        # Print contents of all generated files\n","        for node_name in node_order:\n","            file_name = f\"{node_name}.txt\"\n","            file_path = WORKING_DIRECTORY / file_name\n","            if file_path.exists():\n","                try:\n","                    with file_path.open(\"r\") as file:\n","                        content = file.read().strip()\n","                        logging.info(f\"\\nContents of {file_name}:\\n{content[:500]}...\\n---\")\n","                except IOError as e:\n","                    logging.error(f\"Error reading {file_name}: {e}\")\n","            else:\n","                logging.warning(f\"File {file_name} was not created during the process\")\n","        \n","    except Exception as e:\n","        logging.error(f\"An unexpected error occurred: {e}\")\n","        logging.exception(\"Detailed traceback:\")\n","    \n","    finally:\n","        logging.info(\"Cleaning up temporary files...\")\n","        for node_name in node_order:\n","            file_name = f\"{node_name}.txt\"\n","            file_path = WORKING_DIRECTORY / file_name\n","            try:\n","                file_path.unlink()\n","                logging.info(f\"Deleted {file_name}\")\n","            except FileNotFoundError:\n","                logging.warning(f\"File {file_name} not found during cleanup\")\n","        \n","        logging.info(\"Process completed.\")\n","        \n","## Logging Info\n","\n","        import logging\n","\n","logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","def create_agent_node(name: str, tools: List[BaseTool], system_prompt: str):\n","    # ... (previous code)\n","    \n","    def execute_agent(state):\n","        logging.debug(f\"Executing agent: {name}\")\n","        logging.debug(f\"Input state: {state}\")\n","        result = AgentExecutor(agent=agent, tools=tools).invoke(state)\n","        logging.debug(f\"Agent result: {result}\")\n","        \n","        # ... (rest of the function)\n","        \n","        logging.debug(f\"Output state: {new_state}\")\n","        return new_state\n","    \n","    return execute_agent\n","\n","# In run_sales_pitch_generator\n","for step, node_name in enumerate(node_order):\n","    try:\n","        logging.debug(f\"Starting execution of node: {node_name}\")\n","        # ... (rest of the code)\n","    except Exception as e:\n","        logging.exception(f\"Detailed error in step {step + 1}:\")\n","        break"]}],"metadata":{"kernelspec":{"display_name":"llmops-course","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}

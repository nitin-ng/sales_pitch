{"cells":[{"cell_type":"markdown","metadata":{},"source":["Installing libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -qU langgraph langchain langchain_openai langchain_community qdrant-client PyPDF2 beautifulsoup4 requests"]},{"cell_type":"markdown","metadata":{},"source":["Setting up imports"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import getpass\n","from typing import List, Dict, Any, Union, Annotated, Optional\n","from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.agents import AgentExecutor, create_openai_functions_agent\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.tools import BaseTool, tool\n","from langgraph.graph import StateGraph, END\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_community.vectorstores import Qdrant\n","import functools\n","import operator\n","from pathlib import Path\n","import uuid\n","import requests\n","from bs4 import BeautifulSoup\n","import PyPDF2\n","import io\n","from qdrant_client import QdrantClient\n","from qdrant_client.http import models as rest\n","\n","# Set up API keys\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n","os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a working directory"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","WORKING_DIRECTORY = Path(\"./content/data\")\n","WORKING_DIRECTORY.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize Qdrant Client and OpenAI Embeddings"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Initialize Qdrant client\n","qdrant_client = QdrantClient(\":memory:\")  # Use in-memory storage for simplicity\n","\n","# Initialize OpenAI embeddings\n","embeddings = OpenAIEmbeddings()"]},{"cell_type":"markdown","metadata":{},"source":["State and Helper functions"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class State(Dict[str, Any]):\n","    messages: Annotated[List[BaseMessage], operator.add]\n","    next: str\n","    documents: Dict[str, str]\n","\n","def get_last_message(state: State) -> str:\n","    return state[\"messages\"][-1].content\n","\n","def join_graph(response: dict):\n","    return {\"messages\": [response[\"messages\"][-1]]}\n","\n","def prelude(state):\n","    written_files = []\n","    try:\n","        written_files = [f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.glob(\"*\")]\n","    except:\n","        pass\n","    if not written_files:\n","        return {**state, \"current_files\": \"No files written.\"}\n","    return {\n","        **state,\n","        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n","        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["Setting up Vector Store"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def initialize_vector_store():\n","    qdrant_client.recreate_collection(\n","        collection_name=\"sales_pitch_data\",\n","        vectors_config=rest.VectorParams(size=1536, distance=rest.Distance.COSINE),\n","    )\n","\n","def add_to_vector_store(text: str, metadata: Dict[str, Any]):\n","    vector = embeddings.embed_query(text)\n","    qdrant_client.upsert(\n","        collection_name=\"sales_pitch_data\",\n","        points=[rest.PointStruct(id=uuid.uuid4().hex, vector=vector, payload=metadata)],\n","    )\n","\n","def query_vector_store(query: str, limit: int = 5) -> List[Dict[str, Any]]:\n","    query_vector = embeddings.embed_query(query)\n","    search_result = qdrant_client.search(\n","        collection_name=\"sales_pitch_data\",\n","        query_vector=query_vector,\n","        limit=limit,\n","    )\n","    return [hit.payload for hit in search_result]"]},{"cell_type":"markdown","metadata":{},"source":["Tools"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["tavily_tool = TavilySearchResults(max_results=5)\n","\n","@tool\n","def linkedin_check(name: str, company: str) -> bool:\n","    \"\"\"Check if a person works at a specific company on LinkedIn.\"\"\"\n","    # Note: This is a mock implementation. In a real scenario, you'd use LinkedIn's API or web scraping.\n","    url = f\"https://www.linkedin.com/search/results/people/?keywords={name} {company}\"\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    return company.lower() in soup.text.lower()\n","\n","@tool\n","def read_document(\n","    file_name: Annotated[str, \"File path to read the document.\"],\n","    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n","    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",") -> str:\n","    \"\"\"Read the specified document.\"\"\"\n","    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n","        lines = file.readlines()\n","    if start is None:\n","        start = 0\n","    return \"\".join(lines[start:end])\n","\n","@tool\n","def write_document(\n","    content: Annotated[str, \"Text content to be written into the document.\"],\n","    state: Annotated[dict, \"The current state of the conversation.\"],\n",") -> Annotated[str, \"Path of the saved document file.\"]:\n","    \"\"\"Create and save a text document.\"\"\"\n","    file_name = state.get(\"output_file\", \"output.txt\")\n","    file_path = WORKING_DIRECTORY / file_name\n","    try:\n","        with file_path.open(\"w\") as file:\n","            file.write(content)\n","        logging.info(f\"Successfully wrote content to {file_path}\")\n","        return f\"Document saved to {file_path}\"\n","    except IOError as e:\n","        logging.error(f\"Error writing to {file_path}: {e}\")\n","        return f\"Error: Could not write to {file_path}\"\n","\n","@tool\n","def upload_document(file_path: str) -> str:\n","    \"\"\"Upload and read a document (PDF or text).\"\"\"\n","    file_extension = Path(file_path).suffix.lower()\n","    if file_extension == '.pdf':\n","        with open(file_path, 'rb') as file:\n","            pdf_reader = PyPDF2.PdfReader(file)\n","            text = \"\"\n","            for page in pdf_reader.pages:\n","                text += page.extract_text()\n","    elif file_extension in ['.txt', '.md']:\n","        with open(file_path, 'r') as file:\n","            text = file.read()\n","    else:\n","        raise ValueError(\"Unsupported file type. Please upload a PDF or text file.\")\n","    \n","    # Save the extracted text to a file in the working directory\n","    output_file = WORKING_DIRECTORY / f\"uploaded_document_{uuid.uuid4()}.txt\"\n","    with output_file.open(\"w\") as file:\n","        file.write(text)\n","    \n","    return f\"Document uploaded and saved as {output_file.name}\"\n","\n","@tool\n","def query_vector_db(query: str) -> str:\n","    \"\"\"Query the vector database for relevant information.\"\"\"\n","    results = query_vector_store(query)\n","    return \"\\n\".join([f\"{item['type']}: {item['content']}\" for item in results])"]},{"cell_type":"markdown","metadata":{},"source":["Agent Creation"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from langchain.agents import AgentExecutor, create_openai_functions_agent\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_openai import ChatOpenAI\n","\n","def create_agent_node(name: str, tools: List[BaseTool], system_prompt: str):\n","    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n","    prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", system_prompt + \"\\n\\nAfter completing your task, you MUST use the write_document tool to save your output to a file named '{output_file}'. Your response should include confirmation that the file was saved.\"),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ])\n","    agent = create_openai_functions_agent(llm, tools, prompt)\n","    \n","    def execute_agent(state):\n","        # Add the output_file to the state\n","        state[\"output_file\"] = f\"{name}.txt\"\n","        result = AgentExecutor(agent=agent, tools=tools).invoke(state)\n","        output = result['output']\n","        \n","        # Ensure 'next' is always set\n","        next_step = name  # Default to current node if not specified\n","        if isinstance(output, dict) and 'next' in output:\n","            next_step = output['next']\n","        elif isinstance(output, str) and 'next:' in output.lower():\n","            next_step = output.lower().split('next:')[-1].strip()\n","        \n","        return {\n","            \"messages\": state[\"messages\"] + [HumanMessage(content=str(output), name=name)],\n","            \"next\": next_step,\n","            \"documents\": state.get(\"documents\", {})\n","        }\n","    \n","    return execute_agent\n","\n","def agent_node(state, agent, name):\n","    result = agent.invoke(state)\n","    \n","    new_state = {\n","        \"messages\": state[\"messages\"] + [HumanMessage(content=result[\"output\"], name=name)],\n","        \"next\": result.get(\"next\", name),  # Default to the current node if 'next' is not set\n","        \"documents\": state.get(\"documents\", {})  # Preserve any existing documents\n","    }\n","    \n","    return new_state"]},{"cell_type":"markdown","metadata":{},"source":["Defining Agent Nodes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define agent nodes\n","company_research_alpha = create_agent_node(\n","    \"CompanyResearchAlpha\",\n","    [tavily_tool, read_document, write_document, upload_document, query_vector_db],\n","    \"You are a company research specialist. Your task is to gather initial information about a target company. \"\n","    \"Ask the user for the company name or to upload a document with company info. \"\n","    \"Create initial documents for company name, description, execs, priorities, and industry priorities.\"\n",")\n","\n","# Company Description Team\n","company_description_research = create_agent_node(\n","    \"CompanyDescriptionResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a company description researcher. Your task is to find and compile a comprehensive description of the company.\"\n",")\n","\n","company_description_writing = create_agent_node(\n","    \"CompanyDescriptionWriting\",\n","    [read_document, write_document],\n","    \"You are a professional writer specializing in company descriptions. Your task is to take the research and craft a well-written company description.\"\n",")\n","\n","company_description_fact_checker = create_agent_node(\n","    \"CompanyDescriptionFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the company description.\"\n",")\n","\n","company_description_copy_editor = create_agent_node(\n","    \"CompanyDescriptionCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the company description has correct grammar, spelling, and tone.\"\n",")\n","\n","# Company Execs Team\n","company_execs_research = create_agent_node(\n","    \"CompanyExecsResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are an executive research specialist. Your task is to find the top 5 C-level executives of the company.\"\n",")\n","\n","company_execs_linkedin_check = create_agent_node(\n","    \"CompanyExecsLinkedInCheck\",\n","    [linkedin_check, read_document, write_document],\n","    \"You are a LinkedIn verification specialist. Your task is to verify if the executives are currently working at the company.\"\n",")\n","\n","company_execs_editor = create_agent_node(\n","    \"CompanyExecsEditor\",\n","    [read_document, write_document],\n","    \"You are an editor. Your task is to finalize the list of company executives, excluding any that are not currently with the company.\"\n",")\n","\n","# Company Priorities Team\n","company_priorities_research = create_agent_node(\n","    \"CompanyPrioritiesResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a company priorities researcher. Your task is to identify the top 3 priorities of the company.\"\n",")\n","\n","company_priorities_fact_checker = create_agent_node(\n","    \"CompanyPrioritiesFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the identified company priorities.\"\n",")\n","\n","company_priorities_copy_editor = create_agent_node(\n","    \"CompanyPrioritiesCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the company priorities are clearly and correctly stated.\"\n",")\n","\n","# Industry Trends Team\n","industry_trends_research = create_agent_node(\n","    \"IndustryTrendsResearch\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are an industry trends researcher. Your task is to identify the industry of the company and its top trends and challenges.\"\n",")\n","\n","industry_trends_fact_checker = create_agent_node(\n","    \"IndustryTrendsFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the identified industry trends and challenges.\"\n",")\n","\n","industry_trends_copy_editor = create_agent_node(\n","    \"IndustryTrendsCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the industry trends and challenges are clearly and correctly stated.\"\n",")\n","\n","# Sales Pitch Team\n","value_proposition_research = create_agent_node(\n","    \"ValuePropositionResearch\",\n","    [tavily_tool, read_document, write_document, upload_document, query_vector_db],\n","    \"You are a value proposition researcher. Your task is to research and outline the value proposition of the user's company.\"\n",")\n","\n","value_proposition_fact_checker = create_agent_node(\n","    \"ValuePropositionFactChecker\",\n","    [tavily_tool, read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the value proposition.\"\n",")\n","\n","value_proposition_copy_editor = create_agent_node(\n","    \"ValuePropositionCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the value proposition is clearly and correctly stated.\"\n",")\n","\n","sales_pitch_creator = create_agent_node(\n","    \"SalesPitchCreator\",\n","    [read_document, write_document, query_vector_db],\n","    \"\"\"You are a sales pitch creator. Your task is to create a compelling sales pitch based on the target company's information and the user's company value proposition.\n","    After creating the pitch, you MUST use the write_document tool to save it as 'final_sales_pitch.txt'.\n","    Your response should include the content of the sales pitch and confirmation that it was saved.\"\"\"\n",")\n","\n","sales_pitch_fact_checker = create_agent_node(\n","    \"SalesPitchFactChecker\",\n","    [read_document, write_document, query_vector_db],\n","    \"You are a fact-checker. Your task is to verify the accuracy of the sales pitch.\"\n",")\n","\n","sales_pitch_copy_editor = create_agent_node(\n","    \"SalesPitchCopyEditor\",\n","    [read_document, write_document],\n","    \"You are a copy editor. Your task is to ensure the sales pitch has correct grammar, spelling, and tone.\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Graph Creation"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from typing import Dict, List, TypedDict\n","from langgraph.graph import StateGraph, END\n","from langchain_core.messages import HumanMessage\n","\n","# Define the state\n","class State(TypedDict):\n","    messages: List[HumanMessage]\n","    next: str\n","\n","# Create the graph\n","graph = StateGraph(State)\n","\n","# Define a dictionary mapping node names to their corresponding functions\n","node_functions = {\n","    \"CompanyResearchAlpha\": company_research_alpha,\n","    \"CompanyDescriptionResearch\": company_description_research,\n","    \"CompanyDescriptionWriting\": company_description_writing,\n","    \"CompanyDescriptionFactChecker\": company_description_fact_checker,\n","    \"CompanyDescriptionCopyEditor\": company_description_copy_editor,\n","    \"CompanyExecsResearch\": company_execs_research,\n","    \"CompanyExecsLinkedInCheck\": company_execs_linkedin_check,\n","    \"CompanyExecsEditor\": company_execs_editor,\n","    \"CompanyPrioritiesResearch\": company_priorities_research,\n","    \"CompanyPrioritiesFactChecker\": company_priorities_fact_checker,\n","    \"CompanyPrioritiesCopyEditor\": company_priorities_copy_editor,\n","    \"IndustryTrendsResearch\": industry_trends_research,\n","    \"IndustryTrendsFactChecker\": industry_trends_fact_checker,\n","    \"IndustryTrendsCopyEditor\": industry_trends_copy_editor,\n","    \"ValuePropositionResearch\": value_proposition_research,\n","    \"ValuePropositionFactChecker\": value_proposition_fact_checker,\n","    \"ValuePropositionCopyEditor\": value_proposition_copy_editor,\n","    \"SalesPitchCreator\": sales_pitch_creator,\n","    \"SalesPitchFactChecker\": sales_pitch_fact_checker,\n","    \"SalesPitchCopyEditor\": sales_pitch_copy_editor\n","}\n","\n","# Define the node order\n","node_order = [\n","    \"CompanyResearchAlpha\",\n","    \"CompanyDescriptionResearch\",\n","    \"CompanyDescriptionWriting\",\n","    \"CompanyDescriptionFactChecker\",\n","    \"CompanyDescriptionCopyEditor\",\n","    \"CompanyExecsResearch\",\n","    \"CompanyExecsLinkedInCheck\",\n","    \"CompanyExecsEditor\",\n","    \"CompanyPrioritiesResearch\",\n","    \"CompanyPrioritiesFactChecker\",\n","    \"CompanyPrioritiesCopyEditor\",\n","    \"IndustryTrendsResearch\",\n","    \"IndustryTrendsFactChecker\",\n","    \"IndustryTrendsCopyEditor\",\n","    \"ValuePropositionResearch\",\n","    \"ValuePropositionFactChecker\",\n","    \"ValuePropositionCopyEditor\",\n","    \"SalesPitchCreator\",\n","    \"SalesPitchFactChecker\",\n","    \"SalesPitchCopyEditor\"\n","]\n","\n","graph = StateGraph(State)\n","\n","# Add nodes to the graph\n","for node in node_order:\n","    graph.add_node(node, node_functions[node])\n","\n","# Add edges between nodes\n","for i in range(len(node_order) - 1):\n","    current_node = node_order[i]\n","    next_node = node_order[i + 1]\n","    graph.add_edge(current_node, next_node)\n","\n","# Add conditional edges for each node\n","for i, node in enumerate(node_order):\n","    next_nodes = {next_node: next_node for next_node in node_order[i+1:]}\n","    next_nodes[\"END\"] = END\n","    \n","    graph.add_conditional_edges(\n","        node,\n","        lambda x: x[\"next\"],\n","        next_nodes\n","    )\n","\n","# Set the entry point\n","graph.set_entry_point(\"CompanyResearchAlpha\")\n","\n","# Compile the graph\n","workflow = graph.compile()"]},{"cell_type":"markdown","metadata":{},"source":["Main Chain and Execution"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-02 16:37:47,236 - INFO - Initializing vector store...\n"]},{"name":"stderr","output_type":"stream","text":["2024-09-02 16:37:57,505 - INFO - Generating sales pitch for Microsoft...\n","2024-09-02 16:37:57,505 - INFO - Executing step 1/20: CompanyResearchAlpha\n","2024-09-02 16:37:57,521 - ERROR - An error occurred during step 1 (CompanyResearchAlpha): \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-02 16:37:57,522 - ERROR - Detailed traceback:\n","Traceback (most recent call last):\n","  File \"/var/folders/jr/_qkyxp313390z32jmym7j9sm0000gp/T/ipykernel_64437/840569170.py\", line 14, in run_sales_pitch_generator\n","    new_state = node_function(state)\n","                ^^^^^^^^^^^^^^^^^^^^\n","  File \"/var/folders/jr/_qkyxp313390z32jmym7j9sm0000gp/T/ipykernel_64437/2955531964.py\", line 15, in execute_agent\n","    result = AgentExecutor(agent=agent, tools=tools).invoke(state)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/chains/base.py\", line 164, in invoke\n","    raise e\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/chains/base.py\", line 154, in invoke\n","    self._call(inputs, run_manager=run_manager)\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/agents/agent.py\", line 1625, in _call\n","    next_step_output = self._take_next_step(\n","                       ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/agents/agent.py\", line 1331, in _take_next_step\n","    [\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/agents/agent.py\", line 1331, in <listcomp>\n","    [\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/agents/agent.py\", line 1359, in _iter_next_step\n","    output = self._action_agent.plan(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain/agents/agent.py\", line 462, in plan\n","    for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3261, in stream\n","    yield from self.transform(iter([input]), config, **kwargs)\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3248, in transform\n","    yield from self._transform_stream_with_config(\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2054, in _transform_stream_with_config\n","    chunk: Output = context.run(next, iterator)  # type: ignore\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3211, in _transform\n","    yield from final_pipeline\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 1272, in transform\n","    for ichunk in input:\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5299, in transform\n","    yield from self.bound.transform(\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 1272, in transform\n","    for ichunk in input:\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 1290, in transform\n","    yield from self.stream(final, config, **kwargs)\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 855, in stream\n","    yield self.invoke(input, config, **kwargs)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/prompts/base.py\", line 186, in invoke\n","    return self._call_with_config(\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 1785, in _call_with_config\n","    context.run(\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/config.py\", line 398, in call_func_with_variable_args\n","    return func(input, **kwargs)  # type: ignore[call-arg]\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/prompts/base.py\", line 160, in _format_prompt_with_error_handling\n","    _inner_input = self._validate_input(inner_input)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/prompts/base.py\", line 156, in _validate_input\n","    raise KeyError(msg)\n","KeyError: \"Input to ChatPromptTemplate is missing variables {'name'}.  Expected: ['agent_scratchpad', 'messages', 'name'] Received: ['messages', 'next', 'documents', 'intermediate_steps', 'agent_scratchpad']\\nNote: if you intended {name} to be part of the string and not a variable, please escape it with double curly braces like: '{{name}}'.\"\n","2024-09-02 16:37:57,526 - ERROR - Final sales pitch file not found\n","2024-09-02 16:37:57,527 - INFO - \n","Final Sales Pitch:\n","2024-09-02 16:37:57,527 - WARNING - File company_description.txt was not created during the process\n","2024-09-02 16:37:57,527 - WARNING - File company_execs.txt was not created during the process\n","2024-09-02 16:37:57,528 - WARNING - File company_priorities.txt was not created during the process\n","2024-09-02 16:37:57,529 - WARNING - File industry_priorities.txt was not created during the process\n","2024-09-02 16:37:57,529 - WARNING - File value_proposition.txt was not created during the process\n","2024-09-02 16:37:57,530 - WARNING - File final_sales_pitch.txt was not created during the process\n","2024-09-02 16:37:57,531 - INFO - Cleaning up temporary files...\n","2024-09-02 16:37:57,531 - WARNING - File company_description.txt not found during cleanup\n","2024-09-02 16:37:57,531 - WARNING - File company_execs.txt not found during cleanup\n","2024-09-02 16:37:57,531 - WARNING - File company_priorities.txt not found during cleanup\n","2024-09-02 16:37:57,532 - WARNING - File industry_priorities.txt not found during cleanup\n","2024-09-02 16:37:57,532 - WARNING - File value_proposition.txt not found during cleanup\n","2024-09-02 16:37:57,532 - WARNING - File final_sales_pitch.txt not found during cleanup\n","2024-09-02 16:37:57,533 - INFO - Process completed.\n"]},{"name":"stdout","output_type":"stream","text":["Final sales pitch file not found. There may have been an error in the process.\n"]}],"source":["def run_sales_pitch_generator(target_company: str, user_company_url: str):\n","    initial_message = f\"Generate a sales pitch for {target_company}. Our company website is {user_company_url}.\"\n","    \n","    state = {\"messages\": [HumanMessage(content=initial_message)], \"next\": \"CompanyResearchAlpha\", \"documents\": {}}\n","    \n","    for step, node_name in enumerate(node_order):\n","        try:\n","            logging.info(f\"Executing step {step + 1}/{len(node_order)}: {node_name}\")\n","            \n","            if node_name not in node_functions:\n","                raise KeyError(f\"Node '{node_name}' not found in node_functions dictionary\")\n","            \n","            node_function = node_functions[node_name]\n","            new_state = node_function(state)\n","            \n","            logging.debug(f\"State after {node_name}: {new_state}\")\n","            \n","            if not isinstance(new_state, dict) or 'messages' not in new_state or 'next' not in new_state:\n","                raise ValueError(f\"Invalid state returned by {node_name}. State: {new_state}\")\n","            \n","            state = new_state\n","            \n","            # Check for file creation after each step\n","            output_file = f\"{node_name}.txt\"\n","            doc_path = WORKING_DIRECTORY / output_file\n","            if doc_path.exists():\n","                logging.info(f\"File {output_file} exists after step {node_name}\")\n","                try:\n","                    with doc_path.open(\"r\") as file:\n","                        content = file.read().strip()\n","                        if content:\n","                            logging.info(f\"\\n{output_file} Contents:\\n{content[:500]}...\\n---\")\n","                        else:\n","                            logging.warning(f\"File {output_file} is empty\")\n","                except IOError as e:\n","                    logging.error(f\"Error reading {output_file}: {e}\")\n","            else:\n","                logging.warning(f\"File {output_file} does not exist after step {node_name}\")\n","            \n","            if state['next'] == \"END\":\n","                break\n","                \n","        except Exception as e:\n","            logging.error(f\"An error occurred during step {step + 1} ({node_name}): {e}\")\n","            logging.exception(\"Detailed traceback:\")\n","            break\n","\n","    # After the chain completes, read and return the final sales pitch\n","    final_pitch_path = WORKING_DIRECTORY / \"SalesPitchCreator.txt\"\n","    if final_pitch_path.exists():\n","        try:\n","            with final_pitch_path.open(\"r\") as file:\n","                return file.read().strip()\n","        except IOError as e:\n","            logging.error(f\"Error reading final sales pitch: {e}\")\n","            return \"Error reading final sales pitch file.\"\n","    else:\n","        logging.error(\"Final sales pitch file not found\")\n","        return \"Final sales pitch file not found. There may have been an error in the process.\"\n","\n","## Main Code Execution Block\n","\n","if __name__ == \"__main__\":\n","    try:\n","        logging.info(\"Initializing vector store...\")\n","        initialize_vector_store()\n","        \n","        while True:\n","            target_company = input(\"Enter the name of the target company: \").strip()\n","            if target_company:\n","                break\n","            print(\"Company name cannot be empty. Please try again.\")\n","        \n","        while True:\n","            user_company_url = input(\"Enter your company's URL: \").strip()\n","            if user_company_url and \".\" in user_company_url:\n","                break\n","            print(\"Please enter a valid URL.\")\n","        \n","        logging.info(f\"Generating sales pitch for {target_company}...\")\n","        final_pitch = run_sales_pitch_generator(target_company, user_company_url)\n","        \n","        logging.info(\"\\nFinal Sales Pitch:\")\n","        print(final_pitch)\n","        \n","        # Print contents of all generated files\n","        for node_name in node_order:\n","            file_name = f\"{node_name}.txt\"\n","            file_path = WORKING_DIRECTORY / file_name\n","            if file_path.exists():\n","                try:\n","                    with file_path.open(\"r\") as file:\n","                        content = file.read().strip()\n","                        logging.info(f\"\\nContents of {file_name}:\\n{content[:500]}...\\n---\")\n","                except IOError as e:\n","                    logging.error(f\"Error reading {file_name}: {e}\")\n","            else:\n","                logging.warning(f\"File {file_name} was not created during the process\")\n","        \n","    except Exception as e:\n","        logging.error(f\"An unexpected error occurred: {e}\")\n","        logging.exception(\"Detailed traceback:\")\n","    \n","    finally:\n","        logging.info(\"Cleaning up temporary files...\")\n","        for node_name in node_order:\n","            file_name = f\"{node_name}.txt\"\n","            file_path = WORKING_DIRECTORY / file_name\n","            try:\n","                file_path.unlink()\n","                logging.info(f\"Deleted {file_name}\")\n","            except FileNotFoundError:\n","                logging.warning(f\"File {file_name} not found during cleanup\")\n","        \n","        logging.info(\"Process completed.\")\n","        \n","## Logging Info\n","\n","        import logging\n","\n","logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","def create_agent_node(name: str, tools: List[BaseTool], system_prompt: str):\n","    # ... (previous code)\n","    \n","    def execute_agent(state):\n","        logging.debug(f\"Executing agent: {name}\")\n","        logging.debug(f\"Input state: {state}\")\n","        result = AgentExecutor(agent=agent, tools=tools).invoke(state)\n","        logging.debug(f\"Agent result: {result}\")\n","        \n","        # ... (rest of the function)\n","        \n","        logging.debug(f\"Output state: {new_state}\")\n","        return new_state\n","    \n","    return execute_agent\n","\n","# In run_sales_pitch_generator\n","for step, node_name in enumerate(node_order):\n","    try:\n","        logging.debug(f\"Starting execution of node: {node_name}\")\n","        # ... (rest of the code)\n","    except Exception as e:\n","        logging.exception(f\"Detailed error in step {step + 1}:\")\n","        break"]}],"metadata":{"kernelspec":{"display_name":"llmops-course","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
